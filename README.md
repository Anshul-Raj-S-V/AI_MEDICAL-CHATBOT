
# üß† AI Medical Chatbot ‚Äî Voice + Vision + Intelligence

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/)
[![Gradio](https://img.shields.io/badge/Gradio-4.x-orange.svg)](https://gradio.app)
[![OpenAI](https://img.shields.io/badge/Meta_LLaMA_4-Instruct-green.svg)](https://ai.meta.com/llama/)
[![Groq](https://img.shields.io/badge/Groq-Whisper_Large_V3-purple.svg)](https://groq.com)
[![ElevenLabs](https://img.shields.io/badge/ElevenLabs-TTS-red.svg)](https://elevenlabs.io)

---

## ü©∫ Overview

**AI Medical Chatbot** is an intelligent **voice-based healthcare assistant** that listens to the patient‚Äôs symptoms, analyzes uploaded **medical images (e.g., X-rays, skin scans)**, and responds **verbally like a real doctor**.  
It combines **speech recognition**, **computer vision**, and **text-to-speech synthesis** to create a natural, conversational medical analysis flow.

> ‚öôÔ∏è Built for educational and research purposes to explore multimodal AI in medical diagnostics.

---

## üß© Core Features

- üéôÔ∏è **Voice-to-Text (Speech Recognition)**  
  Uses **Groq‚Äôs Whisper-Large-V3** model for highly accurate and real-time medical speech transcription.

- üñºÔ∏è **Image Understanding (Vision + LLM)**  
  Analyzes medical images via **Meta LLaMA 4 Scout 17B** to provide contextual health insights.

- üßë‚Äç‚öïÔ∏è **AI Doctor Response Generation**  
  The system crafts a concise, empathetic doctor-like response‚Äîavoiding robotic or AI-style phrasing.

- üîä **Text-to-Speech (Doctor‚Äôs Voice)**  
  Uses **ElevenLabs TTS** or **Google TTS (fallback)** to deliver lifelike medical advice in a natural tone.

- üí¨ **Interactive Gradio Interface**  
  A clean web UI for recording voice, uploading images, and listening to the AI doctor‚Äôs spoken feedback.

---

## üß† System Architecture

```mermaid
graph TD;
    A[üé§ Patient Speech] -->|Groq Whisper| B[üßæ Text Transcript]
    B --> C[ü©∫ Meta LLaMA 4 - Vision + Text Analysis]
    C --> D[üßë‚Äç‚öïÔ∏è Doctor-like Response]
    D -->|ElevenLabs / gTTS| E[üîä Audio Output]
    E --> F[üíª Gradio UI Display]
````

---

## ‚öôÔ∏è Tech Stack

| Component                    | Technology Used                 |
| ---------------------------- | ------------------------------- |
| **Frontend (UI)**            | Gradio 4.x                      |
| **Speech Recognition (STT)** | Groq API ‚Äì Whisper Large V3     |
| **Vision + Reasoning**       | Meta LLaMA 4 Scout 17B Instruct |
| **Text-to-Speech (TTS)**     | ElevenLabs API / Google gTTS    |
| **Environment Variables**    | python-dotenv                   |
| **Audio Processing**         | pydub                           |
| **Language**                 | Python 3.11+                    |

---

## üöÄ Installation & Setup

### 1Ô∏è‚É£ Clone the Repository

```bash
git clone https://github.com/<your-username>/AI_MEDICAL_CHATBOT.git
cd AI_MEDICAL_CHATBOT
```

### 2Ô∏è‚É£ Create a Virtual Environment

```bash
python -m venv venv
venv\Scripts\activate  # for Windows
# source venv/bin/activate  # for Linux/Mac
```

### 3Ô∏è‚É£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4Ô∏è‚É£ Set Up Environment Variables

Create a `.env` file in the project root and add:

```bash
GROQ_API_KEY=your_groq_api_key
ELEVEN_API_KEY=your_elevenlabs_api_key
```

### 5Ô∏è‚É£ Run the App

```bash
python main.py
```

Then open the Gradio UI at:
üëâ [http://127.0.0.1:7860](http://127.0.0.1:7860)

---

## üßë‚Äçüíª Project Structure

```bash
AI_MEDICAL_CHATBOT/
‚îÇ
‚îú‚îÄ‚îÄ brain.py                  # Image encoding + AI analysis logic
‚îú‚îÄ‚îÄ voice_of_patient.py       # Records + transcribes patient speech
‚îú‚îÄ‚îÄ voice_of_doctor.py        # Generates and plays doctor's voice
‚îú‚îÄ‚îÄ main.py                   # Gradio UI integration
‚îú‚îÄ‚îÄ .env                      # API keys (keep private)
‚îú‚îÄ‚îÄ requirements.txt          # Project dependencies
‚îú‚îÄ‚îÄ README.md                 # Project documentation
‚îî‚îÄ‚îÄ venv/                     # Virtual environment (ignored in Git)
```

---

## üß¨ Example Flow

1. üé§ The patient speaks their symptoms (recorded via microphone).
2. üß† The system transcribes speech ‚Üí interprets image ‚Üí generates a concise diagnosis.
3. üîä The doctor‚Äôs response is converted to natural voice using ElevenLabs and played automatically.

---

## ‚ö†Ô∏è Disclaimer

> ‚öïÔ∏è **This project is for learning and demonstration purposes only.**
> It is **not intended for real medical use or diagnosis.**
> Always consult a licensed medical professional for any health concerns.

---


> *‚ÄúAI won‚Äôt replace doctors, but doctors who use AI will replace those who don‚Äôt.‚Äù*

---

```

